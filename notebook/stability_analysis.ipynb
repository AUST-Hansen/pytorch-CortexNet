{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define video file name\n",
    "file_name = '/media/atcold/VIDEODATA/video-dataset/data/car/20160706_180451.mp4'\n",
    "\n",
    "# create an iterator over the video frames\n",
    "frame_iterator = skvideo.io.vreader(file_name)\n",
    "\n",
    "# load the whole video\n",
    "video_data = skvideo.io.vread(file_name)\n",
    "\n",
    "# print video_data shape\n",
    "print('The video_data has shape:', video_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display N frames: 1st, ..., ..., last\n",
    "def showSamples(data, N=4, height=12):\n",
    "    rows = np.floor(N ** 0.5)\n",
    "    columns = N / rows\n",
    "    for p in range(0, N):\n",
    "        plt.subplot(rows, columns, p + 1)\n",
    "        idx = p * (data.shape[0] - 1) // (N - 1) if N > 1 else 0\n",
    "        plt.imshow(data[idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "    s = data.shape\n",
    "    plt.gcf().set_size_inches((height*s[2]/s[1]/rows, height/columns))\n",
    "    \n",
    "showSamples(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some image processing exploration\n",
    "IN_SIZE = 224  # define a constant\n",
    "img = video_data[0]  # get first frame\n",
    "print('The input image has size', img.shape)\n",
    "scaling_factor = max(IN_SIZE / img.shape[0], IN_SIZE / img.shape[1])\n",
    "img_rescaled = rescale(img, scaling_factor)\n",
    "print('The rescaled image has size', img_rescaled.shape)\n",
    "r = ((img_rescaled.shape[0] - IN_SIZE) / 2, (img_rescaled.shape[1] - IN_SIZE) / 2, 0)\n",
    "r = tuple((np.floor(z), np.ceil(z)) for z in r)\n",
    "img_cropped_1 = crop(img_rescaled, r)\n",
    "img_cropped_2 = crop(img_rescaled, r, copy=True)\n",
    "print('The cropped image has size', img_cropped_1.shape)\n",
    "print('img_cropped_1 is contiguous:', img_cropped_1.flags['C_CONTIGUOUS'])\n",
    "print('img_cropped_2 is contiguous:', img_cropped_2.flags['C_CONTIGUOUS'])\n",
    "plt.imshow(img_cropped_2); plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preproces the whole video\n",
    "processed_data = np.ndarray((video_data.shape[0], IN_SIZE, IN_SIZE, video_data.shape[3]), dtype=np.float32)\n",
    "for frame in range(0, video_data.shape[0]):\n",
    "    processed_data[frame] = crop(rescale(video_data[frame], scaling_factor), r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "showSamples(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define some utility function\n",
    "def to_torch(x):\n",
    "    dim = x.ndim\n",
    "    if dim == 3:\n",
    "        return torch.from_numpy(skimage.img_as_float(x).astype(np.float32).transpose(2, 0, 1))\n",
    "    elif dim == 4:\n",
    "        return torch.from_numpy(skimage.img_as_float(x).astype(np.float32).transpose(0, 3, 1, 2))\n",
    "    else:\n",
    "        raise ValueError('Bad input dimensionality, dim:', dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert data from numpy to torch\n",
    "torch_data = to_torch(processed_data)\n",
    "print(torch_data.type())\n",
    "print(torch_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalise the input data\n",
    "def normalise(x):\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    for c in range(0, 3):\n",
    "        x[:,c,:,:].sub_(mean[c]).div_(std[c])\n",
    "    return x\n",
    "        \n",
    "norm_data = normalise(torch_data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print some stats\n",
    "for i, c in enumerate(('red', 'green', 'blue')):\n",
    "    print(c, 'stats:')\n",
    "    r = torch_data[:,i,:,:]\n",
    "    print('min: {:.3f}, max: {:.3f}, mean: {:.3f}, std: {:.3f}'.format(r.min(), r.max(), r.mean(), r.std()))\n",
    "    r = norm_data[:,i,:,:]\n",
    "    print('min: {:.3f}, max: {:.3f}, mean: {:.3f}, std: {:.3f}'.format(r.min(), r.max(), r.mean(), r.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get classes\n",
    "file_name = 'synset_words.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_URL = 'https://github.com/szagoruyko/functional-zoo/raw/master/synset_words.txt'\n",
    "    os.system('wget ' + synset_URL)\n",
    "\n",
    "classes = list()\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        classes.append(line.strip().split(' ', 1)[1].split(', ')[0])\n",
    "classes = tuple(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print first 5 classes and indeces\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(i, classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "# get network\n",
    "\n",
    "resnet_18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet_18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable as V\n",
    "from torch.nn import functional as f\n",
    "\n",
    "# forward first frame\n",
    "\n",
    "x = V(norm_data.narrow(0, 0, 1), volatile=True)\n",
    "x = V(tr_center_crop(video_data[0]))\n",
    "logit = resnet_18.forward(x)\n",
    "h_x = f.softmax(logit).data.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "# set back background\n",
    "\n",
    "plt.style.use(['dark_background'])\n",
    "rc('figure', figsize=(16, 8), facecolor='none')\n",
    "rc('axes', facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(h_x)), h_x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs, idx = h_x.sort(0, True)\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs, idx = h_x.sort(0, True)\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "\n",
    "# verify net health\n",
    "\n",
    "file_name = '26132.jpg'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    file_URL = 'http://www.zooclub.ru/attach/26000/26132.jpg'\n",
    "    os.system('wget ' + file_URL)\n",
    "img = skimage.io.imread(file_name)\n",
    "\n",
    "scaling_factor = max(IN_SIZE / img.shape[0], IN_SIZE / img.shape[1])\n",
    "img_rescaled = rescale(img, scaling_factor)\n",
    "r = ((img_rescaled.shape[0] - IN_SIZE) / 2, (img_rescaled.shape[1] - IN_SIZE) / 2, 0)\n",
    "r = tuple((np.floor(z), np.ceil(z)) for z in r)\n",
    "img_cropped = crop(img_rescaled, r)\n",
    "plt.imshow(img_cropped); plt.axis('off')\n",
    "\n",
    "img_torch = normalise(to_torch(img_cropped).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = V(img_torch, volatile=True)\n",
    "logit = resnet_18.forward(x)\n",
    "h_x = f.softmax(logit).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "for i in range(0, 5):\n",
    "    print(probs[i], classes[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_torch.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as f\n",
    "\n",
    "\n",
    "# define image transformation\n",
    "tr_center_crop = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "probs, idx = f.softmax(resnet_18.forward(V(tr_center_crop(img).unsqueeze(0), volatile=True))).data.view(-1).sort(0, True)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(probs[i], classes[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
