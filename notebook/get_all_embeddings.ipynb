{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get classes\n",
    "data_set_path = 'data_set'\n",
    "classes = [\n",
    "        c for c in os.listdir(data_set_path)\n",
    "        if not c.startswith('.')\n",
    "        and os.path.isdir(os.path.join(data_set_path, c))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get video files\n",
    "video_dict = dict()\n",
    "for class_ in classes:\n",
    "    class_path = os.path.join(data_set_path, class_)\n",
    "    video_dict[class_] = tuple(\n",
    "            v for v in os.listdir(class_path)\n",
    "            if not v.startswith('.')\n",
    "            and os.path.isfile(os.path.join(class_path, v))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trun off vertical list printing\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the content of a specific class\n",
    "video_dict.get('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# get network\n",
    "resnet_18 = models.resnet18(pretrained=True)\n",
    "resnet_18.eval();\n",
    "resnet_18.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms as trn\n",
    "\n",
    "# define image transformation\n",
    "pre_proc = trn.Compose([\n",
    "        trn.ToPILImage(),\n",
    "        trn.Scale(256),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create hook\n",
    "avgpool_layer = resnet_18._modules.get('avgpool')\n",
    "h = avgpool_layer.register_forward_hook(lambda m,i,o: my_embedding.append(o.data.view(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "from torch.nn.functional import softmax\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "from skvideo.io import FFmpegReader\n",
    "\n",
    "embedding_and_probs_dict = dict()\n",
    "\n",
    "# for c, class_ in enumerate(classes):\n",
    "class_ = 'car'\n",
    "embedding_and_probs_dict[class_] = dict()\n",
    "class_path = os.path.join(data_set_path, class_)\n",
    "\n",
    "video_nb = len(video_dict[class_])\n",
    "video_prg_bar = IntProgress(min=0, max=video_nb, bar_style='success',\n",
    "                            description='video 1/' + str(video_nb))\n",
    "display(video_prg_bar)\n",
    "frame_prg_bar = IntProgress(min=0, max=0, description='frame'); display(frame_prg_bar)\n",
    "for video_name in video_dict[class_]:\n",
    "    video_prg_bar.description = 'video ' + str(video_prg_bar.value+1) + '/' + str(len(video_dict[class_]))\n",
    "    # start at a given index\n",
    "#     if video_prg_bar.value < 21:\n",
    "#         video_prg_bar.value += 1\n",
    "#         video_prg_bar.description = 'video ' + str(video_prg_bar.value+1) + '/' + str(len(video_dict[class_]))\n",
    "#         continue\n",
    "    video_path = os.path.join(class_path, video_name)\n",
    "    video_file = FFmpegReader(video_path)\n",
    "    frames_nb = video_file.getShape()[0]\n",
    "    my_embedding = list()\n",
    "    my_probabilities = list()\n",
    "\n",
    "    frame_prg_bar.max = frames_nb\n",
    "    frame_prg_bar.value = 0\n",
    "    frame_prg_bar.description = 'frame 1/' + str(frames_nb)\n",
    "    \n",
    "    for frame in video_file.nextFrame():\n",
    "        frame_prg_bar.description = 'frame ' + str(frame_prg_bar.value+1) + '/' + str(frames_nb)\n",
    "        x = V(pre_proc(frame).unsqueeze(0).cuda(), volatile=True)\n",
    "        logit = resnet_18(x)\n",
    "        my_probabilities.append(softmax(logit).data)\n",
    "        frame_prg_bar.value += 1\n",
    "        # hack for buggy video files\n",
    "        if video_name == 'V60722-191627.mp4' and frame_prg_bar.value + 1 == frames_nb: break\n",
    "\n",
    "    embedding_and_probs_dict[class_][video_name] = {\n",
    "            'emb': torch.cat(my_embedding, 0).cpu(),\n",
    "            'prb': torch.cat(my_probabilities, 0).cpu()\n",
    "    }\n",
    "    video_prg_bar.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(embedding_and_probs_dict, 'emb_prb.pth.tar')\n",
    "# embedding_and_probs_dict = torch.load('emb_prb.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove hook\n",
    "h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get classes labels\n",
    "classes_file_name = 'synset_words.txt'\n",
    "if not os.access(classes_file_name, os.W_OK):\n",
    "    synset_URL = 'https://github.com/szagoruyko/functional-zoo/raw/master/synset_words.txt'\n",
    "    os.system('wget ' + synset_URL)\n",
    "\n",
    "classes = list()\n",
    "with open(classes_file_name) as f:\n",
    "    for line in f:\n",
    "        classes.append(line.strip().split(' ', 1)[1].split(', ')[0])\n",
    "classes = tuple(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return top N indeces\n",
    "def get_top_n_idx(p, N=5):\n",
    "    probs, idx = p.sort(0, True)\n",
    "    return idx[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matplotlib and stuff\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "\n",
    "# configurations for dark background\n",
    "plt.style.use(['dark_background', 'bmh'])\n",
    "\n",
    "# configuration for bright background\n",
    "# plt.style.use('bmh')\n",
    "\n",
    "# remove background colour, set figure size\n",
    "rc('figure', figsize=(16, 8), facecolor='none', max_open_warning=False)\n",
    "rc('axes', facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the car_embedding Tensor\n",
    "car_embedding = torch.cat(tuple(embedding_and_probs_dict['car'][a_key]['prb']\n",
    "        for a_key in embedding_and_probs_dict['car'].keys()), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "\n",
    "# perform PCA on car_embedding\n",
    "mlab_pca = mlabPCA(car_embedding.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "marker = itertools.cycle(('>', (5, 0), (5, 1), (5, 2)))\n",
    "\n",
    "# draw all car_embedding,\n",
    "# video probability over frame index\n",
    "# video bubble and embedding probability\n",
    "i = 0\n",
    "fig_count = 2\n",
    "for a_key in embedding_and_probs_dict['car'].keys():\n",
    "    # prepare the data\n",
    "    prob_mat = embedding_and_probs_dict['car'][a_key]['prb']\n",
    "    samples = prob_mat.size(0)\n",
    "    video_mean_prob = prob_mat.mean(dim=0).squeeze()\n",
    "    top_n_ind = get_top_n_idx(video_mean_prob, 5)\n",
    "    top_n_classes = prob_mat.index_select(1, top_n_ind)\n",
    "    top_n_classes_np = top_n_classes.numpy()\n",
    "    \n",
    "    ### figure 2k, k > 1 ###################\n",
    "    plt.figure(fig_count); fig_count += 1\n",
    "    plt.plot(top_n_classes_np)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.legend([classes[idx] for idx in top_n_ind], loc='upper left');\n",
    "    plt.title(a_key)\n",
    "\n",
    "    ### figure 2k+1, k > 1 #################\n",
    "    plt.figure(fig_count); fig_count += 1\n",
    "    plt.plot(mlab_pca.Y[i:i+samples,0],mlab_pca.Y[i:i+samples,1], c='white', linewidth=0.25, zorder=1)\n",
    "    plt.scatter(mlab_pca.Y[i:i+samples,0],mlab_pca.Y[i:i+samples,1], c=top_n_classes_np[:,0],\n",
    "                s=180, vmin=0, vmax=1, zorder=2)\n",
    "    plt.colorbar(fraction=0.025, pad=0.01)\n",
    "    plt.title(a_key)\n",
    "    \n",
    "    ### figure 1 ###########################\n",
    "    plt.figure(1)\n",
    "    plt.scatter(mlab_pca.Y[i:i+samples,0],mlab_pca.Y[i:i+samples,1], marker=next(marker), label=a_key)\n",
    "    i += samples\n",
    "\n",
    "plt.legend()\n",
    "plt.title('car space')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "07bbd9f28fb1400aa497b7e9667ef35b": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "22ab2d1622834414ac6dc79f5b2a2d7a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "6db65d2344c7466ca5e02ffe6a3928e8": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "d5b0b305813f43fda41e054f84027dea": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
