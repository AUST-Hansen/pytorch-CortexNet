{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable as V\n",
    "from utils.visualise import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resnet_18 = torchvision.models.resnet18(pretrained=True)\n",
    "resnet_18.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# by setting the volatile flag to True, intermediate caches are not saved\n",
    "# making the inspection of the graph pretty boring / useless\n",
    "torch.manual_seed(0)\n",
    "x = V(torch.randn(1, 3, 224, 224))#, volatile=True)\n",
    "h_x = resnet_18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot = make_dot(h_x)  # generate network graph\n",
    "dot.render('net.dot');  # save DOT and PDF in the current directory\n",
    "# dot  # uncomment for displaying the graph in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_x creator -> <torch.nn._functions.linear.Linear object at 0x10cf46508>\n",
      "h_x creator prev fun type -> <class 'tuple'>\n",
      "h_x creator prev fun length -> 3\n",
      "\n",
      "--- content of h_x creator prev fun ---\n",
      "0 --> (<torch.autograd._functions.tensor.View object at 0x10cf46470>, 0)\n",
      "1 --> (Parameter containing:\n",
      "-1.8474e-02 -7.0461e-02 -5.1772e-02  ...  -3.9030e-02  1.7351e-01 -4.0976e-02\n",
      "-8.1792e-02 -9.4370e-02  1.7355e-02  ...   2.0284e-01 -2.4782e-02  3.7172e-02\n",
      "-3.3164e-02 -5.6569e-02 -2.4165e-02  ...  -3.4402e-02 -2.2659e-02  1.9705e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0300e-02  3.2804e-03 -3.5863e-02  ...  -2.7923e-02 -1.1458e-02  1.2759e-02\n",
      "-3.5879e-02 -3.5296e-02 -2.9602e-02  ...  -3.2961e-02 -1.1022e-02 -5.1256e-02\n",
      " 2.1277e-03 -2.4839e-02 -8.2920e-02  ...   4.1731e-02 -5.0030e-02  6.6327e-02\n",
      "[torch.FloatTensor of size 1000x512]\n",
      ", 0)\n",
      "2 --> (Parameter containing:\n",
      "1.00000e-02 *\n",
      " -0.2634\n",
      "  0.3000\n",
      "  0.0656\n",
      "    ⋮   \n",
      " -1.7868\n",
      " -0.0782\n",
      " -0.6345\n",
      "[torch.FloatTensor of size 1000]\n",
      ", 0)\n",
      "---------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore network graph\n",
    "print('h_x creator ->',h_x.creator)\n",
    "print('h_x creator prev fun type ->', type(h_x.creator.previous_functions))\n",
    "print('h_x creator prev fun length ->', len(h_x.creator.previous_functions))\n",
    "print('\\n--- content of h_x creator prev fun ---')\n",
    "for a, b in enumerate(h_x.creator.previous_functions): print(a, '-->', b)\n",
    "print('---------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current node is a `torch.nn._functions.linear.Linear` object, fed by\n",
    "\n",
    "- 0 --> output of `torch.autograd._functions.tensor.View` object\n",
    "- 1 --> weight matrix of size `(1000, 512)`\n",
    "- 2 --> bias vector of size `(1000)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet (\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (relu): ReLU (inplace)\n",
      "  (maxpool): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "  (layer1): Sequential (\n",
      "    (0): BasicBlock (\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "    (1): BasicBlock (\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential (\n",
      "    (0): BasicBlock (\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (downsample): Sequential (\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock (\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential (\n",
      "    (0): BasicBlock (\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (downsample): Sequential (\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock (\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential (\n",
      "    (0): BasicBlock (\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (downsample): Sequential (\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock (\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d (\n",
      "  )\n",
      "  (fc): Linear (512 -> 1000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet_18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 'avgpool', 'fc'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_18._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: <class 'torch.nn.modules.pooling.AvgPool2d'> \n",
      "i: <class 'tuple'> \n",
      "   len: 1 \n",
      "   type: <class 'torch.autograd.variable.Variable'> \n",
      "   data size: torch.Size([1, 512, 7, 7]) \n",
      "   data type: torch.FloatTensor \n",
      "o: <class 'torch.autograd.variable.Variable'> \n",
      "   data size: torch.Size([1, 512, 1, 1]) \n",
      "   data type: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "avgpool_layer = resnet_18._modules.get('avgpool')\n",
    "h = avgpool_layer.register_forward_hook(\n",
    "        lambda m, i, o: \\\n",
    "        print(\n",
    "            'm:', type(m),\n",
    "            '\\ni:', type(i),\n",
    "                '\\n   len:', len(i),\n",
    "                '\\n   type:', type(i[0]),\n",
    "                '\\n   data size:', i[0].data.size(),\n",
    "                '\\n   data type:', i[0].data.type(),\n",
    "            '\\no:', type(o),\n",
    "                '\\n   data size:', o.data.size(),\n",
    "                '\\n   data type:', o.data.type(),\n",
    "        )\n",
    ")\n",
    "h_x = resnet_18(x)\n",
    "h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_embedding = torch.zeros(512)\n",
    "def fun(m, i, o): my_embedding.copy_(o.data)\n",
    "h = avgpool_layer.register_forward_hook(fun)\n",
    "h_x = resnet_18(x)\n",
    "h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3879  0.0205  0.0268  2.9453  0.0234  0.0000  0.0000  0.7327  1.0997  0.0000\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first values of the embedding\n",
    "my_embedding[:10].view(1, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
